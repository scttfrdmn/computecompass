/**
 * Vector Database Initialization Service
 * 
 * Populates the vector database with comprehensive data including:
 * - AWS instance specifications and hardware details
 * - Performance benchmark results and analysis
 * - Research workload patterns and templates
 * - Cost optimization case studies and insights
 */

import { VectorDatabaseService } from './vector-database'
import { AWSService } from './aws-service'
import { BenchmarkDataService } from './benchmark-data'
import type {
  VectorDocument,
  VectorDatabaseConfig,
  DocumentType,
  DocumentMetadata,
} from '../types/rag-system'
import type { InstanceType, BenchmarkData } from '../types/aws-types'
import type { WorkloadPattern } from '../types/consumption'
import { WORKLOAD_TEMPLATES } from '../data/workload-templates'

/**
 * Service for initializing and populating the vector database
 */
export class VectorDatabaseInitService {
  private static isInitialized = false
  private static populationStats = {
    instances: 0,
    benchmarks: 0,
    workloads: 0,
    caseStudies: 0,
    performancePatterns: 0,
    totalDocuments: 0
  }

  /**
   * Initialize and populate the vector database with all available data
   */
  static async initializeAndPopulate(config: VectorDatabaseConfig): Promise<void> {
    console.log('üöÄ Initializing vector database with comprehensive research data...')
    
    // Initialize the vector database
    await VectorDatabaseService.initialize(config)
    
    // Clear any existing data for fresh start
    await VectorDatabaseService.clearDatabase()
    
    // Populate with different data types in parallel for efficiency
    await Promise.all([
      this.populateInstanceSpecifications(),
      this.populateBenchmarkData(),
      this.populateWorkloadPatterns(),
      this.populateOptimizationCaseStudies(),
      this.populatePerformancePatterns()
    ])
    
    // Generate final statistics
    const stats = await VectorDatabaseService.getStatistics()
    this.populationStats.totalDocuments = stats.totalDocuments
    
    this.isInitialized = true
    
    console.log('‚úÖ Vector database initialization completed!')
    console.log('üìä Population Statistics:', this.populationStats)
  }

  /**
   * Populate AWS instance specifications with enhanced metadata
   */
  private static async populateInstanceSpecifications(): Promise<void> {
    console.log('üìù Populating AWS instance specifications...')
    
    try {
      // Get comprehensive instance data from AWS service
      const instances = await AWSService.getInstanceTypes()
      
      const documents: Omit<VectorDocument, 'embedding'>[] = instances.map(instance => ({
        id: `instance-spec-${instance.InstanceType}`,
        type: 'instance_specification',
        content: this.createInstanceSpecificationContent(instance),
        metadata: this.createInstanceSpecificationMetadata(instance),
        lastUpdated: new Date()
      }))
      
      await VectorDatabaseService.addDocuments(documents)
      this.populationStats.instances = documents.length
      
      console.log(`‚úÖ Added ${documents.length} instance specifications`)
      
    } catch (error) {
      console.error('‚ùå Error populating instance specifications:', error)
    }
  }

  /**
   * Populate performance benchmark data with detailed analysis
   */
  private static async populateBenchmarkData(): Promise<void> {
    console.log('üèÉ Populating performance benchmark data...')
    
    try {
      // Check if benchmark data is available
      if (!BenchmarkDataService.isDataAvailable()) {
        console.log('‚ö†Ô∏è Benchmark data not available, generating synthetic data...')
        await this.generateSyntheticBenchmarkData()
        return
      }
      
      // Get real benchmark data
      const benchmarkData = await BenchmarkDataService.fetchBenchmarkData()
      
      const documents: Omit<VectorDocument, 'embedding'>[] = []
      
      // Create documents for each benchmark result
      for (const [instanceType, data] of Object.entries(benchmarkData.instances)) {
        if (data.benchmarks) {
          for (const [suite, results] of Object.entries(data.benchmarks)) {
            documents.push({
              id: `benchmark-${instanceType}-${suite}`,
              type: 'benchmark_result',
              content: this.createBenchmarkContent(instanceType, suite, results),
              metadata: this.createBenchmarkMetadata(instanceType, suite, results),
              lastUpdated: new Date()
            })
          }
        }
      }
      
      await VectorDatabaseService.addDocuments(documents)
      this.populationStats.benchmarks = documents.length
      
      console.log(`‚úÖ Added ${documents.length} benchmark results`)
      
    } catch (error) {
      console.error('‚ùå Error populating benchmark data:', error)
      await this.generateSyntheticBenchmarkData()
    }
  }

  /**
   * Populate research workload patterns and templates
   */
  private static async populateWorkloadPatterns(): Promise<void> {
    console.log('üî¨ Populating research workload patterns...')
    
    try {
      // Use existing workload templates
      const workloads = WORKLOAD_TEMPLATES
      
      const documents: Omit<VectorDocument, 'embedding'>[] = workloads.map(workload => ({
        id: `workload-pattern-${workload.id}`,
        type: 'workload_template',
        content: this.createWorkloadPatternContent(workload),
        metadata: this.createWorkloadPatternMetadata(workload),
        lastUpdated: new Date()
      }))
      
      // Add additional domain-specific patterns
      const domainPatterns = this.generateDomainSpecificPatterns()
      documents.push(...domainPatterns)
      
      await VectorDatabaseService.addDocuments(documents)
      this.populationStats.workloads = documents.length
      
      console.log(`‚úÖ Added ${documents.length} workload patterns`)
      
    } catch (error) {
      console.error('‚ùå Error populating workload patterns:', error)
    }
  }

  /**
   * Populate cost optimization case studies
   */
  private static async populateOptimizationCaseStudies(): Promise<void> {
    console.log('üí∞ Populating cost optimization case studies...')
    
    try {
      const caseStudies = this.generateOptimizationCaseStudies()
      
      const documents: Omit<VectorDocument, 'embedding'>[] = caseStudies.map((study, index) => ({
        id: `case-study-${index + 1}`,
        type: 'optimization_case_study',
        content: study.content,
        metadata: study.metadata,
        lastUpdated: new Date()
      }))
      
      await VectorDatabaseService.addDocuments(documents)
      this.populationStats.caseStudies = documents.length
      
      console.log(`‚úÖ Added ${documents.length} optimization case studies`)
      
    } catch (error) {
      console.error('‚ùå Error populating case studies:', error)
    }
  }

  /**
   * Populate performance patterns and insights
   */
  private static async populatePerformancePatterns(): Promise<void> {
    console.log('‚ö° Populating performance patterns...')
    
    try {
      const patterns = this.generatePerformancePatterns()
      
      const documents: Omit<VectorDocument, 'embedding'>[] = patterns.map((pattern, index) => ({
        id: `performance-pattern-${index + 1}`,
        type: 'performance_pattern',
        content: pattern.content,
        metadata: pattern.metadata,
        lastUpdated: new Date()
      }))
      
      await VectorDatabaseService.addDocuments(documents)
      this.populationStats.performancePatterns = documents.length
      
      console.log(`‚úÖ Added ${documents.length} performance patterns`)
      
    } catch (error) {
      console.error('‚ùå Error populating performance patterns:', error)
    }
  }

  /**
   * Generate synthetic benchmark data when real data is unavailable
   */
  private static async generateSyntheticBenchmarkData(): Promise<void> {
    const syntheticBenchmarks = [
      {
        instanceType: 'm7i.large',
        suite: 'STREAM',
        results: { memory_bandwidth: 25600, memory_latency: 65 },
        content: 'STREAM benchmark on m7i.large shows excellent memory performance with 25.6 GB/s bandwidth and 65ns latency, ideal for memory-intensive genomics workloads.'
      },
      {
        instanceType: 'c7i.xlarge',
        suite: 'LINPACK',
        results: { compute_performance: 45.2, parallel_efficiency: 0.92 },
        content: 'LINPACK results for c7i.xlarge demonstrate 45.2 GFLOPS compute performance with 92% parallel efficiency, excellent for HPC applications.'
      },
      {
        instanceType: 'r7i.2xlarge',
        suite: 'STREAM',
        results: { memory_bandwidth: 51200, memory_latency: 58 },
        content: 'Memory-optimized r7i.2xlarge achieves 51.2 GB/s bandwidth with low 58ns latency, perfect for in-memory analytics and large datasets.'
      },
      {
        instanceType: 'p4d.24xlarge',
        suite: 'MLPerf',
        results: { training_throughput: 1250, gpu_utilization: 0.95 },
        content: 'P4d.24xlarge with 8x A100 GPUs delivers 1250 samples/sec training throughput with 95% GPU utilization, optimized for large-scale ML training.'
      }
    ]
    
    const documents: Omit<VectorDocument, 'embedding'>[] = syntheticBenchmarks.map(bench => ({
      id: `synthetic-benchmark-${bench.instanceType}-${bench.suite}`,
      type: 'benchmark_result',
      content: bench.content,
      metadata: {
        source: 'ComputeCompass Synthetic Benchmarks',
        category: 'performance_benchmark',
        instanceTypes: [bench.instanceType],
        performanceMetrics: Object.keys(bench.results),
        benchmarkSuite: bench.suite,
        reliability: 0.8, // Lower reliability for synthetic data
        dateRelevance: 0.9,
        testConditions: {
          environment: 'virtualized',
          softwareVersion: bench.suite === 'MLPerf' ? 'v2.1' : 'standard'
        }
      },
      lastUpdated: new Date()
    }))
    
    await VectorDatabaseService.addDocuments(documents)
    this.populationStats.benchmarks = documents.length
    
    console.log(`‚úÖ Added ${documents.length} synthetic benchmark results`)
  }

  /**
   * Generate domain-specific workload patterns
   */
  private static generateDomainSpecificPatterns(): Omit<VectorDocument, 'embedding'>[] {
    const domainPatterns = [
      {
        domain: 'Computational Biology',
        pattern: 'Protein folding simulations require high memory bandwidth and long-running computations. Memory-optimized instances like r7i family are preferred with sustained CPU utilization over 12-48 hours.',
        instanceTypes: ['r7i.large', 'r7i.xlarge', 'r7i.2xlarge'],
        workloadTypes: ['protein_folding', 'molecular_dynamics', 'bioinformatics']
      },
      {
        domain: 'Climate Modeling',
        pattern: 'Weather and climate simulations need massive parallel computing with MPI. Compute-optimized instances with enhanced networking perform best for distributed workloads.',
        instanceTypes: ['c7i.4xlarge', 'c7i.8xlarge', 'c7i.16xlarge'],
        workloadTypes: ['climate_simulation', 'weather_modeling', 'atmospheric_research']
      },
      {
        domain: 'Machine Learning',
        pattern: 'Deep learning training benefits from GPU acceleration with high memory capacity. P4d instances with A100 GPUs provide optimal price-performance for large models.',
        instanceTypes: ['p4d.24xlarge', 'p3.16xlarge', 'g5.12xlarge'],
        workloadTypes: ['deep_learning', 'neural_networks', 'ai_training']
      },
      {
        domain: 'Financial Modeling',
        pattern: 'Monte Carlo simulations and risk analysis require sustained CPU performance with low latency. Compute-optimized instances with consistent performance are ideal.',
        instanceTypes: ['c7i.2xlarge', 'c7i.4xlarge', 'm7i.2xlarge'],
        workloadTypes: ['monte_carlo', 'risk_analysis', 'financial_modeling']
      }
    ]
    
    return domainPatterns.map((pattern, index) => ({
      id: `domain-pattern-${index + 1}`,
      type: 'workload_template',
      content: `${pattern.domain}: ${pattern.pattern}`,
      metadata: {
        source: 'ComputeCompass Domain Analysis',
        category: 'domain_pattern',
        instanceTypes: pattern.instanceTypes,
        workloadTypes: pattern.workloadTypes,
        reliability: 0.9,
        dateRelevance: 0.95,
        researchDomain: pattern.domain.toLowerCase().replace(/\s+/g, '_')
      },
      lastUpdated: new Date()
    }))
  }

  /**
   * Generate optimization case studies
   */
  private static generateOptimizationCaseStudies() {
    return [
      {
        content: 'University genomics lab reduced costs by 35% by switching from all on-demand to 70% Reserved Instances + 30% Spot. Mixed strategy maintained reliability while optimizing for budget constraints.',
        metadata: {
          source: 'ComputeCompass Case Studies',
          category: 'cost_optimization',
          instanceTypes: ['m7i.large', 'c7i.xlarge'],
          workloadTypes: ['genomics', 'bioinformatics'],
          reliability: 0.95,
          dateRelevance: 0.9,
          costSavings: 35
        }
      },
      {
        content: 'Climate research consortium achieved 50% cost reduction by implementing burst-optimized strategy with minimal Reserved base + aggressive Spot usage for fault-tolerant simulations.',
        metadata: {
          source: 'ComputeCompass Case Studies',
          category: 'cost_optimization',
          instanceTypes: ['c7i.4xlarge', 'c7i.8xlarge'],
          workloadTypes: ['climate_modeling', 'simulation'],
          reliability: 0.9,
          dateRelevance: 0.85,
          costSavings: 50
        }
      },
      {
        content: 'ML research lab optimized GPU costs by using Savings Plans for steady workloads + Spot instances for experimentation, reducing training costs by 40% while maintaining research velocity.',
        metadata: {
          source: 'ComputeCompass Case Studies',
          category: 'cost_optimization',
          instanceTypes: ['p4d.24xlarge', 'g5.12xlarge'],
          workloadTypes: ['machine_learning', 'deep_learning'],
          reliability: 0.92,
          dateRelevance: 0.95,
          costSavings: 40
        }
      }
    ]
  }

  /**
   * Generate performance patterns
   */
  private static generatePerformancePatterns() {
    return [
      {
        content: 'Memory bandwidth scaling patterns show diminishing returns above 4 NUMA nodes. Single-socket instances often provide better price-performance for memory-intensive workloads than multi-socket alternatives.',
        metadata: {
          source: 'ComputeCompass Performance Analysis',
          category: 'performance_pattern',
          performanceMetrics: ['memory_bandwidth', 'numa_topology'],
          reliability: 0.88,
          dateRelevance: 0.9
        }
      },
      {
        content: 'GPU utilization patterns indicate that batch size optimization can improve training throughput by 25-40%. Larger batch sizes on P4d instances achieve better GPU memory utilization.',
        metadata: {
          source: 'ComputeCompass Performance Analysis',
          category: 'performance_pattern',
          instanceTypes: ['p4d.24xlarge', 'p3.16xlarge'],
          performanceMetrics: ['gpu_utilization', 'training_throughput'],
          workloadTypes: ['machine_learning'],
          reliability: 0.9,
          dateRelevance: 0.95
        }
      },
      {
        content: 'Network performance scaling shows linear improvement with instance size for distributed workloads. Enhanced networking on compute-optimized instances provides 2-3x better MPI performance.',
        metadata: {
          source: 'ComputeCompass Performance Analysis',
          category: 'performance_pattern',
          instanceTypes: ['c7i.large', 'c7i.xlarge', 'c7i.2xlarge'],
          performanceMetrics: ['network_throughput', 'mpi_latency'],
          workloadTypes: ['distributed_computing'],
          reliability: 0.92,
          dateRelevance: 0.9
        }
      }
    ]
  }

  /**
   * Create comprehensive instance specification content
   */
  private static createInstanceSpecificationContent(instance: InstanceType): string {
    const vCpus = instance.VCpuInfo?.DefaultVCpus || 'unknown'
    const memory = instance.MemoryInfo?.SizeInMiB ? Math.round(instance.MemoryInfo.SizeInMiB / 1024) : 'unknown'
    const architecture = instance.ProcessorInfo?.SupportedArchitectures?.join(', ') || 'unknown'
    const network = instance.NetworkInfo?.NetworkPerformance || 'standard'
    const storage = instance.InstanceStorageInfo?.TotalSizeInGB || 'EBS-only'
    const gpu = instance.GpuInfo?.Gpus?.map(g => `${g.Count}x ${g.Name}`).join(', ') || 'none'
    
    return `AWS ${instance.InstanceType} instance specification: ${vCpus} vCPUs, ${memory} GiB memory, ${architecture} architecture.
            Network performance: ${network}. Storage: ${storage}${storage !== 'EBS-only' ? ' GB local SSD' : ''}. GPU: ${gpu}.
            ${this.getInstanceUseCase(instance.InstanceType!)}`
  }

  /**
   * Create enhanced instance specification metadata
   */
  private static createInstanceSpecificationMetadata(instance: InstanceType): DocumentMetadata {
    return {
      source: 'AWS EC2 API',
      category: 'instance_specification',
      instanceTypes: [instance.InstanceType!],
      reliability: 1.0,
      dateRelevance: 1.0
    }
  }

  /**
   * Create benchmark content with analysis
   */
  private static createBenchmarkContent(instanceType: string, suite: string, results: any): string {
    const metrics = Object.entries(results)
      .map(([metric, value]) => `${metric}: ${value}`)
      .join(', ')
    
    return `Performance benchmark results for ${instanceType} using ${suite} suite: ${metrics}. 
            ${this.getBenchmarkAnalysis(instanceType, suite, results)}`
  }

  /**
   * Create benchmark metadata
   */
  private static createBenchmarkMetadata(instanceType: string, suite: string, results: any): DocumentMetadata {
    return {
      source: `${suite} Benchmark Suite`,
      category: 'performance_benchmark',
      instanceTypes: [instanceType],
      performanceMetrics: Object.keys(results),
      benchmarkSuite: suite,
      reliability: 0.95,
      dateRelevance: 0.9
    }
  }

  /**
   * Create workload pattern content
   */
  private static createWorkloadPatternContent(workload: any): string {
    return `Research workload: ${workload.name} - ${workload.description}.
            Resource requirements: ${workload.requirements?.minVCpus || 'flexible'} vCPUs, 
            ${workload.requirements?.minMemoryGiB || 'flexible'} GiB memory.
            ${workload.requirements?.gpuRequired ? 'GPU acceleration required.' : 'CPU-based processing.'}
            Typical use cases: ${workload.category} research, ${workload.description}`
  }

  /**
   * Create workload pattern metadata
   */
  private static createWorkloadPatternMetadata(workload: any): DocumentMetadata {
    return {
      source: 'ComputeCompass Research Templates',
      category: 'workload_pattern',
      workloadTypes: [workload.category],
      reliability: 0.95,
      dateRelevance: 0.9,
      researchDomain: workload.category
    }
  }

  /**
   * Get instance use case description
   */
  private static getInstanceUseCase(instanceType: string): string {
    const family = instanceType.split('.')[0]
    
    const useCases: Record<string, string> = {
      'm7i': 'Ideal for general-purpose workloads, web applications, and balanced compute needs.',
      'c7i': 'Optimized for compute-intensive applications, HPC, and distributed processing.',
      'r7i': 'Best for memory-intensive applications, in-memory databases, and big data analytics.',
      'p4d': 'Designed for machine learning training, AI workloads, and GPU-accelerated computing.',
      'p3': 'Suitable for deep learning training, high-performance computing, and scientific modeling.',
      'g5': 'Optimized for graphics workstations, game streaming, and ML inference.',
      't3': 'Burstable performance for variable workloads and development environments.'
    }
    
    return useCases[family] || 'Suitable for various research computing workloads.'
  }

  /**
   * Get benchmark analysis
   */
  private static getBenchmarkAnalysis(instanceType: string, suite: string, results: any): string {
    if (suite === 'STREAM' && results.memory_bandwidth) {
      if (results.memory_bandwidth > 40000) {
        return 'Excellent memory performance, ideal for memory-bound applications.'
      } else if (results.memory_bandwidth > 20000) {
        return 'Good memory performance, suitable for most data-intensive workloads.'
      } else {
        return 'Moderate memory performance, best for compute-intensive applications.'
      }
    }
    
    if (suite === 'LINPACK' && results.compute_performance) {
      if (results.compute_performance > 100) {
        return 'High compute performance, excellent for CPU-intensive workloads.'
      } else if (results.compute_performance > 50) {
        return 'Good compute performance for parallel applications.'
      } else {
        return 'Moderate compute performance, suitable for general workloads.'
      }
    }
    
    return 'Performance characteristics suitable for research computing workloads.'
  }

  /**
   * Get current population statistics
   */
  static getPopulationStats() {
    return { ...this.populationStats }
  }

  /**
   * Check if database is initialized and populated
   */
  static isVectorDatabaseReady(): boolean {
    return this.isInitialized && this.populationStats.totalDocuments > 0
  }

  /**
   * Refresh database with latest data
   */
  static async refreshDatabase(): Promise<void> {
    if (!this.isInitialized) {
      throw new Error('Database not initialized. Call initializeAndPopulate() first.')
    }
    
    console.log('üîÑ Refreshing vector database with latest data...')
    
    // Clear existing data
    await VectorDatabaseService.clearDatabase()
    
    // Reset stats
    this.populationStats = {
      instances: 0,
      benchmarks: 0,
      workloads: 0,
      caseStudies: 0,
      performancePatterns: 0,
      totalDocuments: 0
    }
    
    // Repopulate
    await Promise.all([
      this.populateInstanceSpecifications(),
      this.populateBenchmarkData(),
      this.populateWorkloadPatterns(),
      this.populateOptimizationCaseStudies(),
      this.populatePerformancePatterns()
    ])
    
    const stats = await VectorDatabaseService.getStatistics()
    this.populationStats.totalDocuments = stats.totalDocuments
    
    console.log('‚úÖ Database refresh completed!')
    console.log('üìä Updated Statistics:', this.populationStats)
  }
}